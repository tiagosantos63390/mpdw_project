# mpdw_project

## âœ… Phase 1 Progress Summary

### 2.1 Video Data and Metadata
- âœ… Parsed **ActivityNet Captions** dataset (`train.json`)
- âœ… Selected 10 videos with the most moments
- âœ… Extracted metadata:
  - `video_id`
  - `timestamps`
  - `captions`
  - `duration`
  - `YouTube URL`

---

### 2.2 Text-Based Search
- âœ… Set up **OpenSearch** and created custom index mappings
- âœ… Defined `caption_bow` field with BM25
- âœ… Indexed all selected video moments (189 total)
- âœ… Tested search with `match` queries (BM25)
- âœ… Verified results from text-based search

---

### 2.3 Embeddings Neighborhood
- âœ… Added `caption_vec` field as `knn_vector` (384-dim)
- âœ… Computed embeddings using `all-MiniLM-L6-v2` (Sentence-BERT)
- âœ… Indexed embeddings in OpenSearch
- âœ… Performed semantic search using KNN vector queries
- âŒ Compared BM25 vs. semantic search results
- âŒ *Embeddings not persisted to file (optional step skipped)*

---

### 2.4 Constrained Embedding Search â€“ **Next Steps**
- âœ… Text based search, e.g., for keyword-based search;
- âœ…Embeddings based search; e.g., for semantic search;
- âœ… Add support for **filterable fields** (e.g. duration, tags)
- âœ… Implement search with **boolean filters** (e.g., `"woman" AND duration < 180s`)
- â¬œ Propose and evaluate optimal index mappings

---

### 2.5 Contextual Embeddings & Self-Attention â€“ **Pending**
- â¬œ Visualize contextual word embeddings (layer-wise)
- â¬œ Analyze positional embeddings (repetition behavior)
- â¬œ Examine self-attention in dual vs. cross encoders
- â¬œ Visualize token attention across layers

---

### 2.6 Persistent Storage
- â¬› *Optional* â€“ not implemented
- ğŸ’¡ Considered unnecessary for the current small dataset

---

**âœ”ï¸ Phase 1 Completion: ~75%**
- All core indexing and search functionality is complete.
- Filtering and embedding visualization to be finalized in upcoming steps.